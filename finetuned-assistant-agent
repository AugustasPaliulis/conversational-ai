{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers==4.57.1\n!pip install trl==0.24.0\n!pip install peft==0.16.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:18:23.280094Z","iopub.execute_input":"2025-12-05T08:18:23.280328Z","iopub.status.idle":"2025-12-05T08:19:52.023325Z","shell.execute_reply.started":"2025-12-05T08:18:23.280305Z","shell.execute_reply":"2025-12-05T08:19:52.022540Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.57.1\n  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.1) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.1) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.1) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.1) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.1) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.1) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.1) (2.32.5)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers==4.57.1)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.1) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.1) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.1) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.1) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.1) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.57.1) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.57.1) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.57.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.57.1) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.57.1) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.57.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.57.1) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.57.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.57.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.57.1) (2024.2.0)\nDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\nSuccessfully installed tokenizers-0.22.1 transformers-4.57.1\nCollecting trl==0.24.0\n  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.24.0) (1.9.0)\nRequirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.24.0) (4.4.1)\nRequirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.11/dist-packages (from trl==0.24.0) (4.57.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.24.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.24.0) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.24.0) (7.1.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.24.0) (6.0.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.24.0) (2.6.0+cu124)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.24.0) (0.36.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.24.0) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.24.0) (3.20.0)\nCollecting pyarrow>=21.0.0 (from datasets>=3.0.0->trl==0.24.0)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.24.0) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.24.0) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.24.0) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.24.0) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.24.0) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.24.0) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.24.0) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.24.0) (2025.10.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.56.1->trl==0.24.0) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.56.1->trl==0.24.0) (0.22.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.24.0) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl==0.24.0) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl==0.24.0) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl==0.24.0) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl==0.24.0) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl==0.24.0) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl==0.24.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl==0.24.0) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.24.0) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.24.0) (2.5.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.24.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.24.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.24.0) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.24.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.24.0) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.24.0) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.24.0) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.24.0) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.24.0) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.24.0) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl==0.24.0) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=3.0.0->trl==0.24.0) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl==0.24.0) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl==0.24.0) (2024.2.0)\nDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trl\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyarrow-22.0.0 trl-0.24.0\nRequirement already satisfied: peft==0.16.0 in /usr/local/lib/python3.11/dist-packages (0.16.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (7.1.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (6.0.3)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (4.57.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (4.67.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (1.9.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (0.5.3)\nRequirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.16.0) (0.36.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft==0.16.0) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft==0.16.0) (2025.10.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft==0.16.0) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft==0.16.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft==0.16.0) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.16.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.16.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.16.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.16.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.16.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.16.0) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.16.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.16.0) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.16.0) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.16.0) (0.22.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.16.0) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft==0.16.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft==0.16.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft==0.16.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft==0.16.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->peft==0.16.0) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.16.0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.16.0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.16.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.16.0) (2025.10.5)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->peft==0.16.0) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Check versions\nimport transformers, trl, peft\nprint(\"transformers:\", transformers.__version__)\nprint(\"trl:\", trl.__version__)\nprint(\"peft:\", peft.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:20:04.847994Z","iopub.execute_input":"2025-12-05T08:20:04.848272Z","iopub.status.idle":"2025-12-05T08:20:35.879385Z","shell.execute_reply.started":"2025-12-05T08:20:04.848247Z","shell.execute_reply":"2025-12-05T08:20:35.878343Z"}},"outputs":[{"name":"stderr","text":"2025-12-05 08:20:15.900121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764922816.106616      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764922816.166816      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"transformers: 4.57.1\ntrl: 0.24.0\npeft: 0.16.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np \nimport json\nimport os\nimport shutil\nimport subprocess\nimport sys\nfrom typing import List\nfrom datasets import Dataset\nimport torch\nimport random\ntorch.manual_seed(3407); random.seed(3407); np.random.seed(3407)\n\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom trl import SFTTrainer, SFTConfig\nfrom peft import LoraConfig, get_peft_model, PeftModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:20:54.047811Z","iopub.execute_input":"2025-12-05T08:20:54.048897Z","iopub.status.idle":"2025-12-05T08:20:58.277017Z","shell.execute_reply.started":"2025-12-05T08:20:54.048870Z","shell.execute_reply":"2025-12-05T08:20:58.276449Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def setup_repo(repo_url: str, repo_name: str, work_dir: str = \"/kaggle/working\"):\n    os.chdir(work_dir)\n    \n    # Remove repo if it exists\n    if os.path.exists(os.path.join(work_dir, repo_name)):\n        shutil.rmtree(os.path.join(work_dir, repo_name))\n    \n    # Clone repo\n    subprocess.run([\"git\", \"clone\", repo_url], check=True)\n    \n    # Move into repo/data\n    os.chdir(os.path.join(repo_name, \"data\"))\n\n\nsetup_repo(\"https://github.com/lkra/dstc11-track5.git\", \"dstc11-track5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:22:20.582778Z","iopub.execute_input":"2025-12-05T08:22:20.583357Z","iopub.status.idle":"2025-12-05T08:22:24.115193Z","shell.execute_reply.started":"2025-12-05T08:22:20.583333Z","shell.execute_reply":"2025-12-05T08:22:24.114548Z"}},"outputs":[{"name":"stderr","text":"Cloning into 'dstc11-track5'...\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"## List all files in the current directory iteratively:\nfor dirname, _, filenames in os.walk('.'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:22:39.767922Z","iopub.execute_input":"2025-12-05T08:22:39.768246Z","iopub.status.idle":"2025-12-05T08:22:39.773868Z","shell.execute_reply.started":"2025-12-05T08:22:39.768224Z","shell.execute_reply":"2025-12-05T08:22:39.773206Z"}},"outputs":[{"name":"stdout","text":"./knowledge_aug_domain_reviews.json\n./knowledge.json\n./output_schema.json\n./knowledge_aug_reviews.json\n./README.md\n./val/labels.json\n./val/logs.json\n./test/labels.json\n./test/logs.json\n./train/logs_bkp.json\n./train/labels.json\n./train/logs.json\n./train/bkp/labels.json\n./train/bkp/logs.json\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"with open('train/logs.json', 'r') as f:\n    train_ds=json.load(f)\n\nwith open('train/labels.json', 'r') as f:\n    labels=json.load(f)\n\nwith open('knowledge.json', 'r') as f:\n    knowledge_base=json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:22:42.344944Z","iopub.execute_input":"2025-12-05T08:22:42.345461Z","iopub.status.idle":"2025-12-05T08:22:42.692148Z","shell.execute_reply.started":"2025-12-05T08:22:42.345425Z","shell.execute_reply":"2025-12-05T08:22:42.691316Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def format_dialogue(dialogue: List[dict]) -> List[dict]: \n    \"\"\"\n    Args:\n    dialogue (List[dict]): A list of dictionaries where each dictionary contains two keys:\n        - 'speaker' (str): A string indicating the speaker of the turn ('U' for user, 'S' for system).\n        - 'text' (str): The text spoken by the respective speaker.\n\n    Returns:\n        List[dict]: A new array with a specific role and content\n\n    \"\"\"\n    # Your solution here\n    messages=[]\n    messages.append({\"role\": \"system\", \"content\": \"You are an assistant.\"}) # TODO: Improve the system prompt\n    \n    for dialogue_element in dialogue:\n        try:\n            role = 'user' if dialogue_element['speaker'] == 'U' else 'system'\n            messages.append({\"role\": role, \"content\": dialogue_element['text']})\n        except:\n            continue\n\n\n    return messages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:28:32.790296Z","iopub.execute_input":"2025-12-05T08:28:32.791138Z","iopub.status.idle":"2025-12-05T08:28:32.795573Z","shell.execute_reply.started":"2025-12-05T08:28:32.791111Z","shell.execute_reply":"2025-12-05T08:28:32.795040Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"* **reformat_dataset:** this function formats our dataset into a structure suitable for conversational language-model training. For each sample, it extracts the dialogue and its associated response, appends the response as a message with the \"system\" role, and adds the resulting message list to a new dataset. Samples that cause errors are skipped. The final output is the Hugging Face Dataset, containing conversations organized as lists of role-content message objects.\n\nNOTE: This function is slightly different from the one in Assignment 1. Here, you only need to access the dialogue and the response.\n","metadata":{}},{"cell_type":"code","source":"def reformat_dataset(dataset, labels_dataset): \n    reformatted_dataset = {\n        \"messages\": []\n    }\n    for sample_index in range(len(dataset)): \n        try:\n            sample_dialogue = format_dialogue(dataset[sample_index])\n            sample_response = labels_dataset[sample_index]['response']\n            sample_dialogue.append({\"role\": \"system\", \"content\": sample_response})\n            \n            reformatted_dataset[\"messages\"].append(sample_dialogue)\n        except:\n            continue\n\n\n    return reformatted_dataset\n\nreformatted_dataset = reformat_dataset(train_ds, labels)\n\ndataset = Dataset.from_dict(reformatted_dataset)\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:39:13.522504Z","iopub.execute_input":"2025-12-05T08:39:13.523248Z","iopub.status.idle":"2025-12-05T08:39:14.402920Z","shell.execute_reply.started":"2025-12-05T08:39:13.523224Z","shell.execute_reply":"2025-12-05T08:39:14.402298Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['messages'],\n    num_rows: 16897\n})"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"From this point on, we have already created the dataset for our training dataset. In the following function, you need to do the same for the validation and test datasets.\n\n* **process_dataset_split:** based on the input string of the function, load the corresponding split and create the dataset using the same process as for the training data.","metadata":{}},{"cell_type":"code","source":"def process_dataset_split(split: str) -> Dataset: \n    \"\"\"Loads, reformats, and processes a dataset split for model training or evaluation.\n\n    This function loads a dataset split (e.g., 'val', 'test') and generates a dataset for it, similar to what we had for the train split.\n\n    Args:\n        split (str): The name of the dataset split to process\n\n    Returns:\n        dataset: A HuggingFace `Dataset` object that contains the preprocessed and reformatted data for the specified split.\n\n    \"\"\"\n    # Your solution here.\n    if split == 'test':\n        with open('test/logs.json', 'r') as f:\n            test_ds=json.load(f)\n        \n        with open('test/labels.json', 'r') as f:\n            test_labels=json.load(f)\n\n    \n        return Dataset.from_dict(reformat_dataset(test_ds, test_labels))\n\n    elif split == 'val':\n        with open('val/logs.json', 'r') as f:\n            val_ds=json.load(f)\n        \n        with open('val/labels.json', 'r') as f:\n            val_labels=json.load(f)\n        \n        return Dataset.from_dict(reformat_dataset(val_ds, val_labels))\n\n    raise ValueError('Split is not correct, it must be either \"val\" or \"test\"')\n\nvalidation_ds = process_dataset_split(\"val\")\ntest_ds = process_dataset_split(\"test\")\n\nvalidation_ds, test_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:39:46.175221Z","iopub.execute_input":"2025-12-05T08:39:46.175862Z","iopub.status.idle":"2025-12-05T08:39:46.392213Z","shell.execute_reply.started":"2025-12-05T08:39:46.175838Z","shell.execute_reply":"2025-12-05T08:39:46.391633Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['messages'],\n     num_rows: 2129\n }),\n Dataset({\n     features: ['messages'],\n     num_rows: 2798\n }))"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"## Fine-Tuning\n\n### Setting up\n\nNow that we have our data ready, we can look at fine-tuning our model. We will be using HuggingFace Transformers. \n\nAs a language model, we will be using __Qwen3-1.7B__. Let's load it!","metadata":{}},{"cell_type":"code","source":"model_id = \"Qwen/Qwen3-1.7B\"\ntok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\nbase = AutoModelForCausalLM.from_pretrained(model_id, dtype=\"auto\", device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2025-12-05T08:52:45.787090Z","iopub.execute_input":"2025-12-05T08:52:45.787398Z","iopub.status.idle":"2025-12-05T08:52:48.172148Z","shell.execute_reply.started":"2025-12-05T08:52:45.787376Z","shell.execute_reply":"2025-12-05T08:52:48.171405Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27efd19cdaca4e02b88c13ce80d479f4"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"peft_cfg = LoraConfig(r=16, \n           lora_alpha=32, \n           lora_dropout = 0.05, \n           bias = \"none\", \n           use_rslora = False, \n           target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\"])\n\nmodel = get_peft_model(base, peft_cfg)","metadata":{"execution":{"iopub.status.busy":"2025-12-05T08:53:45.802318Z","iopub.execute_input":"2025-12-05T08:53:45.803325Z","iopub.status.idle":"2025-12-05T08:53:46.220301Z","shell.execute_reply.started":"2025-12-05T08:53:45.803292Z","shell.execute_reply":"2025-12-05T08:53:46.219735Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def pick_bf16():\n    if torch.cuda.is_available():\n        major, _ = torch.cuda.get_device_capability()\n        return major >= 8\n    return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:54:10.152512Z","iopub.execute_input":"2025-12-05T08:54:10.152831Z","iopub.status.idle":"2025-12-05T08:54:10.156862Z","shell.execute_reply.started":"2025-12-05T08:54:10.152808Z","shell.execute_reply":"2025-12-05T08:54:10.156130Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"NUM_TRAIN_EPOCHS = 2\nLEARNING_RATE    = 0.0003\nWARMUP_STEPS     = 300\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nsft_args = SFTConfig(\n    output_dir=\"outputs\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    learning_rate=LEARNING_RATE,\n    warmup_steps=WARMUP_STEPS,\n    num_train_epochs=NUM_TRAIN_EPOCHS,\n    logging_steps=10,\n    lr_scheduler_type=\"linear\",\n    weight_decay=0.01,\n    max_length=1024,\n    optim=\"adamw_torch_fused\",\n    fp16=not pick_bf16(),\n    bf16=pick_bf16(),\n    packing=False,\n    dataset_num_proc=2,\n    report_to=\"none\",\n    seed=3407\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:54:35.553686Z","iopub.execute_input":"2025-12-05T08:54:35.554453Z","iopub.status.idle":"2025-12-05T08:54:35.588032Z","shell.execute_reply.started":"2025-12-05T08:54:35.554428Z","shell.execute_reply":"2025-12-05T08:54:35.587297Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"Let’s define our trainer object using the parameters we set earlier.","metadata":{}},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,      \n    eval_dataset=validation_ds,\n    args=sft_args,\n    processing_class=tok\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:54:52.711872Z","iopub.execute_input":"2025-12-05T08:54:52.712161Z","iopub.status.idle":"2025-12-05T08:55:09.404939Z","shell.execute_reply.started":"2025-12-05T08:54:52.712141Z","shell.execute_reply":"2025-12-05T08:55:09.404271Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/16897 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4e5c4a5af64d1681f731763c527476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset (num_proc=2):   0%|          | 0/16897 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7175f37851094595b63a393d834909ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset (num_proc=2):   0%|          | 0/2129 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e661e781c9446b29b0ea971d4b03412"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating eval dataset (num_proc=2):   0%|          | 0/2129 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a21b73bd93d84a23af93a3a4a71deee8"}},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"Now, let’s train the model. Depending on the number of epochs, the process may take between 2 to 6 hours.","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T15:28:46.228201Z","iopub.execute_input":"2024-10-14T15:28:46.228521Z","iopub.status.idle":"2024-10-14T18:33:46.207255Z","shell.execute_reply.started":"2024-10-14T15:28:46.228487Z","shell.execute_reply":"2024-10-14T18:33:46.205894Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Finally, save your trained model in the output/adapter directory.\n\nYou can then download it for future use.","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"outputs/adapter\")  \ntok.save_pretrained(\"outputs/adapter\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<span style=\"background:yellow\">__Q2:__ Print the values for the three parameters you defined in your tuning procedure. Use the sft_args object to access the values.</span> ","metadata":{}},{"cell_type":"code","source":"# Your coding solution here.\nprint(\"NUM_TRAIN_EPOCHS: \", sft_args.##Your answer here##)\nprint(\"LEARNING_RATE: \", sft_args.##Your answer here##)\nprint(\"WARMUP_STEPS: \", sft_args.##Your answer here##)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:00:58.755516Z","iopub.execute_input":"2025-08-06T14:00:58.755902Z","iopub.status.idle":"2025-08-06T14:00:58.760148Z","shell.execute_reply.started":"2025-08-06T14:00:58.755861Z","shell.execute_reply":"2025-08-06T14:00:58.759088Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Now let's take a look at what our fine-tuned model does! ","metadata":{}},{"cell_type":"code","source":"base_model_id = \"Qwen/Qwen3-1.7B\"\nadapter_path  = \"outputs/adapter\" ","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:34:11.034445Z","iopub.execute_input":"2024-10-14T18:34:11.035087Z","iopub.status.idle":"2024-10-14T18:34:14.386523Z","shell.execute_reply.started":"2024-10-14T18:34:11.035049Z","shell.execute_reply":"2024-10-14T18:34:14.385698Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load the base model.","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\nmodel_base = AutoModelForCausalLM.from_pretrained(base_model_id, torch_dtype=\"auto\", device_map=\"auto\")\nmodel_base_for_adapter = AutoModelForCausalLM.from_pretrained(base_model_id, torch_dtype=\"auto\", device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:34:25.212346Z","iopub.execute_input":"2024-10-14T18:34:25.213109Z","iopub.status.idle":"2024-10-14T18:34:28.32913Z","shell.execute_reply.started":"2024-10-14T18:34:25.21307Z","shell.execute_reply":"2024-10-14T18:34:28.328247Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, load the finetuned model from outputs/adapter.","metadata":{}},{"cell_type":"code","source":"model = PeftModel.from_pretrained(model_base_for_adapter, adapter_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T18:34:33.062985Z","iopub.execute_input":"2024-10-14T18:34:33.063776Z","iopub.status.idle":"2024-10-14T18:34:36.26044Z","shell.execute_reply.started":"2024-10-14T18:34:33.063736Z","shell.execute_reply":"2024-10-14T18:34:36.259618Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, let's generate outputs for a dialog using the base model and the finetuned model.","metadata":{}},{"cell_type":"code","source":"dialogue = test_ds[0]['messages'][:-1]\nresponse = test_ds[0]['messages'][-1]\n\ndialogue, response","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text = tokenizer.apply_chat_template(dialogue, tokenize=False, add_generation_prompt=True, enable_thinking=False)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model_base.device)\n\ngenerated_ids = model_base.generate(**model_inputs, max_new_tokens=500)\noutput_ids = generated_ids[0][model_inputs.input_ids.shape[1]:]\n\nprint(\"Base Model: \", tokenizer.decode(output_ids, skip_special_tokens=True).strip())\nprint(\"Ground-truth: \", response[\"content\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text = tokenizer.apply_chat_template(dialogue, tokenize=False, add_generation_prompt=True, enable_thinking=False)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\ngenerated_ids = model.generate(**model_inputs, max_new_tokens=500)\noutput_ids = generated_ids[0][model_inputs.input_ids.shape[1]:]\n\nprint(\"Finetuned Model: \", tokenizer.decode(output_ids, skip_special_tokens=True).strip())\nprint(\"Ground-truth: \", response[\"content\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Analyze Model Responses\nNow that we have our model up and running, let's look at what types of generations the fine-tuned model produces and compare them with the generations of the vanilla model. For this, we will use samples from the test set. Pick the first 10 samples from the __test dataset__ for the analysis and use those to answer the questions below. \n\nNote: Please print the outputs of these 10 examples.\n\n#### Questions\n\nPlease answer each question with a single paragraph, consisting of 2-5 sentences. Include examples to support your answers.\n","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background:yellow\">__Q3:__ What values for the following hyperparameters did you set: number of epochs, learning rate, and warmup steps? Explain briefly why you chose these parameters. </span>\n","metadata":{}},{"cell_type":"markdown","source":"```\n# Your answer here\n```","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background:yellow\">__Q4:__ What is the training loss you achieved, what is its trend over the iterations, and what does this mean for your model? </span>","metadata":{}},{"cell_type":"markdown","source":"```\n# Your answer here\n```","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background:yellow\">__Q5:__ Compare the off-the-shelf to the fine-tuned model: What do you notice in terms of quality of the generation? Are the generations responding to the query?</span> \n","metadata":{}},{"cell_type":"markdown","source":"```\n# Your answer here\n```","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background:yellow\">__Q6:__ Repeat the experiment with a different hyperparameter value for number of epochs, learning rate, or warmup steps. Fine-tune the model using these new settings, and describe your observations regarding the training loss, as well as the quality of the model’s answers to the questions from the test dataset.</span> \n","metadata":{}},{"cell_type":"markdown","source":"```\n# Your answer here\n```","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background:yellow\">__Q7:__ How does the fine-tuned model perform in the following scenarios? Compare this to your answer about the vanilla model in assignment 1.</span> \n1. When all reviews agree with each other\n2. When only one review disagrees\n3. When opinions in the reviews are mixed (i.e. high disagreement)","metadata":{}},{"cell_type":"markdown","source":"```\n# Your answer here\n```","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background:yellow\">__Q8:__ How does the length of the dialogue/conversation history affect the fine-tuned model's generation? Compare this to your answer about the vanilla model in assignment 1.</span> ","metadata":{}},{"cell_type":"markdown","source":"```\n# Your answer here\n```","metadata":{}},{"cell_type":"markdown","source":"<span style=\"background:yellow\">__Q9:__ Create 5 samples that come from a different domain (e.g., airports, shops, web-stores; you can use an LLM or search the web for this). How does the fine-tuned LLM perform on these, compared to the dialogues in the DSTC-11 task5 domains?</span> ","metadata":{}},{"cell_type":"markdown","source":"```\n# Your answer here\n```","metadata":{}}]}